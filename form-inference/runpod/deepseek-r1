# For creation, make sure you attach a volume with model installed and also expose port 8000 in settings
pip install huggingface_hub


apt update && apt install tmux && apt install nvtop
mv /root/.cache /workspace/.cache && ln -s /workspace/.cache /root/.cache

pip install "sglang[all]>=0.4.5" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python

python3 -m sglang.launch_server --model models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B --tp 4 --trust-remote-code --port 8000 --host 0.0.0.0
python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 4 --port 8000 --host 0.0.0.0

curl --request POST \
  --url http://127.0.0.1:59238/generate \
  --header 'Content-Type: application/json' \
  --data '{
 "text": "Write me a 1000 word story",
 "sampling_params": {
  "max_new_tokens": 5000,
  "temperature": 0.7
 },
 "stop_at_limit": false,
 "stream": true
}'